# Лабораторная работа 5 — «Учёт расходов»

## Введение и цель
Цель — отработать потоковую обработку файлов, комбинирование ADO.NET и EF Core для разных задач, работу с большими JSON/XML файлами и формирование агрегированных отчётов.

## Описание задачи (общая концепция)
Необходимо создать приложение **ExpenseTracker**, которое:
- Импортирует транзакции из текстового файла `transactions.txt` (или JSONL `transactions_sample.jsonl`), где каждая запись содержит Date, Category, Amount, Note.
- Сохраняет транзакции в базу данных через ADO.NET и EF Core (в зависимости от сценария).
- Формирует месячные агрегированные отчёты в `YYYY-MM-summary.json` и/или `YYYY-MM-summary.xml` (сумма по категориям).
- Поддерживает быстрые агрегатные запросы через ADO.NET и гибкие фильтры через EF.

## Структура данных — сущность Transaction
Рекомендуемая модель (C#):
```csharp
public class Transaction
{
    public int Id { get; set; }
    public DateTime Date { get; set; }
    public string Category { get; set; }
    public decimal Amount { get; set; }
    public string Note { get; set; }
}
```

## Задания
### Задание 1
**Цель:** импорт простого текстового файла и генерация месячного отчёта.
**Требуется:**
1. Прочитать `transactions.txt` построчно и распарсить поля (Date, Category, Amount, Note).
2. Через ADO.NET вставить записи в таблицу `Transactions`.
3. Сгенерировать месячный отчёт `YYYY-MM-summary.json` и/или `YYYY-MM-summary.xml` — сумма по категориям за указанный месяц.
4. Логирование: количество импортированных записей, обнаруженные ошибки.

---
### Задание 2
**Цель:** EF Core для фильтрации и пагинации; ADO.NET для быстрого агрегирования.
**Требуется:**
1. Создать EF Core модель `Transaction` и `TransactionsContext`. Добавить миграции.
2. Реализовать API или консольные команды для: сортировки, пагинации (page/size), фильтрации по дате/категории.
3. Написать быстрый агрегатный запрос через ADO.NET (например, SUM по Category за период) и возвращать результат в JSON (в виде файла или в консоль).
4. Экспорт выборки в `transactions_export.xml` и `transactions_export.json`.

---
### Задание 3*
**Цель:** потоковый парсинг большого JSONL файла и батчевый импорт.
**Требуется:**
1. Реализовать потоковый парсер для `transactions_sample.jsonl` (по одной JSON-записи на строку) без загрузки всего файла в память. Подсказка: `Utf8JsonReader` или `JsonDocument` в сочетании со `StreamReader`/`FileStream`.
2. Валидация входящих записей (проверка обязательных полей, корректности даты/суммы). Некорректные записи логировать в `errors.json` и пропускать.
3. Батчевый импорт в БД: пакетная вставка (для SQL Server можно использовать `SqlBulkCopy`; для SQLite — выполнение многокомандных INSERT в одной транзакции).
4. Замерить время выполнения импорта (элементарный тайминг) и зафиксировать в лог-файле.

---
### Задание 4*
**Цель:** синхронизация потоков и тестирование.
**Требуется:**
1. Реализовать синхронизацию данных, поступающих из XML и JSON источников (например, XML и JSONL), объединение с дедупликацией по хешу (например, SHA256 полей Date+Category+Amount+Note).
2. Логика разрешения конфликтов: выбирать более "свежную" запись по дате или по приоритету источника.
3. Написать unit- и интеграционные тесты для сценариев импорта и дедупликации (xUnit).

---
